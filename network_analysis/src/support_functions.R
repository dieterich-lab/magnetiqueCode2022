#Copyright (C) 2019  Aurelien Dugourd
#Contact : aurelien.dugourd@bioquant.uni-heidelberg.de

#This program is free software: you can redistribute it and/or modify
#it under the terms of the GNU General Public License as published by
#the Free Software Foundation, either version 3 of the License, or
#(at your option) any later version.

#This program is distributed in the hope that it will be useful,
#but WITHOUT ANY WARRANTY; without even the implied warranty of
#MERCHANTABILITY or FITNESS FOR A PARTICULAR PURPOSE.  See the
#GNU General Public License for more details.

#You should have received a copy of the GNU General Public License
#along with this program.  If not, see <http://www.gnu.org/licenses/>.

#'\code{nicePCA}
#'
#'This function generate a 3*3 arrangeGrob plot object (that can be subsequently diplayed or saved).
#'Each cell of the 3*3 plot grid correspond to a specific representation of the result of a principal component analysis performed on a measurment dataframe.
#'The first input is a n*m data.frame, where n is the number of measured omic features (genes, proteins, metabolites...) and m is the number of samples.
#'The second input is a basic n*2 target dataframe (such as generated by the generateTarget function), where n is the number of samples.
#'
#'@param df the measurment n*m dataframe (n is number of omic features, m is number of samples) where columns are ordered by conditions.
#'@param targets A n*2 dataframe, where n is the number of samples. First column correspond to samples, second column correspond to conditions.
#'@param components a vector of three integers, corresponding to the components to be plotted
#'@param centering a boolean parameter to indicate wether samples should be mean centered
#'@param scaling a boolean parameter to indicate wether samples should be scaled (x/variance)
#'@param pointSize an integer parameter to indicate the desired point size for the components scatter plots.
#'@return an 3*3 arrangeGrob object containing various graphical representation of the result of a PCA.
nicePCA <- function(df, targets, components = c(1,2,3), centering  = T, scaling = F, pointSize = 4, no_label = FALSE)
{  
  if (!is.null(targets))
  {
    df_and_targets <- make_df_and_targets_great_again(df,targets)
    df <- df_and_targets[[1]]
    targets <- df_and_targets[[2]]
  }
  
  sample <- names(df)
  pca <- prcomp(t(df[complete.cases(df),]), center = centering, scale. = scaling)
  explained <- (pca$sdev)^2 / sum(pca$sdev^2)
  
  xCompLab <- paste(paste("PC",components[1], sep = "")," (", sep = "")
  yCompLab <- paste(paste("PC",components[2], sep = "")," (", sep = "")
  zCompLab <- paste(paste("PC",components[3], sep = "")," (", sep = "")
  
  data.to.plot <- as.data.frame(cbind(pca$x[,components[1]], pca$x[,components[2]], pca$x[,components[3]]))
  if ("color" %in% names(targets))
  {
    data.to.plot$condition <- targets$color
  }
  else
  {
    data.to.plot$condition <- targets$condition
  }
  data.to.plot$sample <- targets$sample
  colnames(data.to.plot) <- c("pc1", "pc2", "pc3","condition", "sample")
  
  comp1 <- ggplot(data.to.plot, aes(x = pc1)) + geom_density(aes(alpha = 0.3)) + theme_minimal() +
    xlab(paste(xCompLab,round(100*explained[components[1]],digits=2),'%)',sep='')) +
    theme(legend.position = "none") +
    scale_x_continuous(position = "top", limits = c(-max(abs(pca$x[,components[1]])),max(abs(pca$x[,components[1]])))) +
    scale_y_continuous(position = "left")
  comp2 <- ggplot(data.to.plot, aes(x = pc2)) + geom_density(aes(alpha = 0.3)) + theme_minimal() +
    xlab(paste(yCompLab,round(100*explained[components[2]],digits=2),'%)',sep='')) +
    theme(legend.position = "none") +
    scale_x_continuous(position = "top", limits = c(-max(abs(pca$x[,components[2]])),max(abs(pca$x[,components[2]])))) +
    scale_y_continuous(position = "right")
  comp3 <- ggplot(data.to.plot, aes(x = pc3)) + geom_density(aes(alpha = 0.3)) + theme_minimal() +
    xlab(paste(zCompLab,round(100*explained[components[3]],digits=2),'%)',sep='')) +
    theme(legend.position = "none") +
    scale_x_continuous(position = "top", limits = c(-max(abs(pca$x[,components[3]])),max(abs(pca$x[,components[3]])))) +
    scale_y_continuous(position = "right")
  
  just_for_legend <- ggplot(data.to.plot, aes(x=pc1, y=pc2, color=condition)) +
    geom_point(size=pointSize, alpha = 0.3) +
    geom_text(aes(label=sample), nudge_y = 1.0, size=6) +
    scale_alpha_discrete(range=c(0.3, 1.0)) +
    #geom_path(arrow=arrow()) +
    theme_minimal() +
    xlab(paste(xCompLab,round(100*explained[components[1]],digits=2),'%)',sep='')) +
    ylab(paste(yCompLab,round(100*explained[components[2]],digits=2),'%)',sep='')) +
    xlim(c(-max(abs(pca$x[,components[1]])),max(abs(pca$x[,components[1]])))) +
    ylim(c(-max(abs(pca$x[,components[2]])),max(abs(pca$x[,components[2]]))))
  
  legend <- get_legend(just_for_legend)
  rm(just_for_legend)
  
  if (no_label)
  {
    comp1vcomp2 <- ggplot(data.to.plot, aes(x=pc1, y=pc2, color=condition)) +
      geom_point(size=pointSize, alpha = 0.3) +
      scale_alpha_discrete(range=c(0.3, 1.0)) +
      #geom_path(arrow=arrow()) +
      theme_minimal() +
      xlab("") +
      ylab(paste(yCompLab,round(100*explained[components[2]],digits=2),'%)',sep='')) +
      ylim(c(-max(abs(pca$x[,components[2]])),max(abs(pca$x[,components[2]])))) + theme(legend.position = "none") +
      scale_x_continuous(position = "top",limits = c(-max(abs(pca$x[,components[1]])),max(abs(pca$x[,components[1]]))))
    
    comp1vcomp3 <- ggplot(data.to.plot, aes(x=pc1, y=pc3, color=condition)) +
      geom_point(size=pointSize, alpha = 0.3) +
      scale_alpha_discrete(range=c(0.3, 1.0)) +
      #geom_path(arrow=arrow()) +
      theme_minimal() +
      xlab("") +
      ylab(paste(zCompLab,round(100*explained[components[3]],digits=2),'%)',sep='')) +
      ylim(c(-max(abs(pca$x[,components[3]])),max(abs(pca$x[,components[3]])))) + theme(legend.position = "none") +
      scale_x_continuous(position = "top", limits = c(-max(abs(pca$x[,components[1]])),max(abs(pca$x[,components[1]]))))
    
    comp2vcomp3 <- ggplot(data.to.plot, aes(x=pc2, y=pc3, color=condition)) +
      geom_point(size=pointSize, alpha = 0.3) +
      scale_alpha_discrete(range=c(0.3, 1.0)) +
      #geom_path(arrow=arrow()) +
      theme_minimal() +
      xlab("") +
      ylab("") +
      scale_y_continuous(position = "right", limits = c(-max(abs(pca$x[,components[3]])),max(abs(pca$x[,components[3]])))) +
      scale_x_continuous(position = "top", limits = c(-max(abs(pca$x[,components[2]])),max(abs(pca$x[,components[2]])))) + theme(legend.position = "none")
  }
  else
  {
    comp1vcomp2 <- ggplot(data.to.plot, aes(x=pc1, y=pc2, color=condition)) +
      geom_point(size=pointSize, alpha = 0.3) +
      geom_text_repel(aes(label=sample), size = 2) +
      scale_alpha_discrete(range=c(0.3, 1.0)) +
      #geom_path(arrow=arrow()) +
      theme_minimal() +
      xlab("") +
      ylab(paste(yCompLab,round(100*explained[components[2]],digits=2),'%)',sep='')) +
      ylim(c(-max(abs(pca$x[,components[2]])),max(abs(pca$x[,components[2]])))) + theme(legend.position = "none") +
      scale_x_continuous(position = "top",limits = c(-max(abs(pca$x[,components[1]])),max(abs(pca$x[,components[1]]))))
    
    comp1vcomp3 <- ggplot(data.to.plot, aes(x=pc1, y=pc3, color=condition)) +
      geom_point(size=pointSize, alpha = 0.3) +
      geom_text_repel(aes(label=sample), size = 2) +
      scale_alpha_discrete(range=c(0.3, 1.0)) +
      #geom_path(arrow=arrow()) +
      theme_minimal() +
      xlab("") +
      ylab(paste(zCompLab,round(100*explained[components[3]],digits=2),'%)',sep='')) +
      ylim(c(-max(abs(pca$x[,components[3]])),max(abs(pca$x[,components[3]])))) + theme(legend.position = "none") +
      scale_x_continuous(position = "top", limits = c(-max(abs(pca$x[,components[1]])),max(abs(pca$x[,components[1]]))))
    
    comp2vcomp3 <- ggplot(data.to.plot, aes(x=pc2, y=pc3, color=condition)) +
      geom_point(size=pointSize, alpha = 0.3) +
      geom_text_repel(aes(label=sample), size = 2) +
      scale_alpha_discrete(range=c(0.3, 1.0)) +
      #geom_path(arrow=arrow()) +
      theme_minimal() +
      xlab("") +
      ylab("") +
      scale_y_continuous(position = "right", limits = c(-max(abs(pca$x[,components[3]])),max(abs(pca$x[,components[3]])))) +
      scale_x_continuous(position = "top", limits = c(-max(abs(pca$x[,components[2]])),max(abs(pca$x[,components[2]])))) + theme(legend.position = "none")
    
  }
  
  #barplot(explained, col = "lightblue")
  explained <- as.data.frame(explained)
  explained$Components <- as.numeric(row.names(explained))
  names(explained)[1] <- "% of explained variance"
  
  boulder <- ggplot(explained, aes(x = Components, y = `% of explained variance` , fill = "red")) +
    geom_col() +
    theme_minimal() +
    scale_y_continuous(position = "right") +
    theme(legend.position = "none", axis.text.x=element_blank(), axis.ticks.x=element_blank()) +
    scale_x_continuous(position = "top", breaks = c(1:length(explained[,1])))
  
  return(arrangeGrob(comp1, legend, boulder,comp1vcomp2, comp2, legend, comp1vcomp3, comp2vcomp3, comp3, ncol = 3))
}

#'\code{make_df_and_targets_great_again}
#'
#'This function Check wether sample names are coherent between the measurment dataframe and the target dataframe. If they are coherent,
#' the target dataframe rows are reordered to match the column order of the measurment dataframe.
#'@param df the measurment n*m dataframe (n is number of omic features, m is number of samples) where columns are ordered by conditions.
#'@param targets A n*2 dataframe, where n is the number of samples. First column correspond to samples, second column correspond to conditions.
#'@return A list, first element is the cleaned measurment dataframe and second element is the cleaned target dataframe.
make_df_and_targets_great_again <- function(df, targets)
{
  names(targets)[c(1,2)] <- c("sample","condition")
  bad_samples <- c(NA)
  i <- 1
  for (sample in names(df))
  {
    if (!(sample %in% targets[,1]))
    {
      bad_samples <- c(bad_samples, sample)
    }
    else
    {
      if (i == 1)
      {
        clean_targets <- as.data.frame(matrix(NA, 1, length(targets[1,])))
        names(clean_targets) <- names(targets)
        clean_targets[1,] <- targets[targets$sample == sample,]
        i <- i+1
      }
      else
      {
        clean_targets <- as.data.frame(rbind(clean_targets,targets[targets$sample == sample,]))
        i <- i+1
      }
    }
  }
  targets <- clean_targets
  if (length(bad_samples) > 1)
  {
    bad_samples <- bad_samples[-1]
    print(paste("These samples were not found : ", bad_samples, sep = ""))
    print(bad_samples)
    df <- df[,!(names(df) %in% bad_samples)]
  }
  return(list(df,targets))
}

#'\code{magicPlotMaker}
#'
#'This function is designed to generate and save a battery of plots aimed at helping visualise a measurments dataframe.
#'The function generate 3 plots to directly visualise measurements in the form of a cloud of points, a series of boxplots and surperimposed density curves.
#'It also genereate a pca plot (using nicePCA unction if a targets table is provided).
#'Finally it generates two heatmap, on directly clustering over the measurments and another one performing a clustring over the cross-correlation matrix of the samples.
#'The plots are directly saved to a folder. Nothing is returned.
#'
#'@param df the measurment n*m dataframe (n is number of omic features, m is number of samples) where columns are ordered by conditions.
#'@param outpath a string indicating which folder should the plot be saved in.
#'@param targets A n*2 dataframe, where n is the number of samples. First column correspond to samples, second column correspond to conditions.
magicPlotMaker <- function(df, outpath = ".", targets = NULL, no_pca_label = FALSE, width = 7, height = 7){
  
  dir.create(outpath, showWarnings = F, recursive = T)
  #setwd(outpath)
  if (!grepl("[/]$",outpath))
  {
    outpath <- paste(outpath,"/",sep ="")
  }
  
  print("Dimension of dataframe :")
  print(dim(df))
  
  if (!is.null(targets))
  {
    df_and_targets <- make_df_and_targets_great_again(df,targets)
    df <- df_and_targets[[1]]
    targets <- df_and_targets[[2]]
  }
  
  ##This part is just to generate the melted dataframe for ggplot
  df$ID <- row.names(df)
  
  melted_df <- reshape::melt(df)
  index <- c(1:length(melted_df[,1]))
  
  df <- df[,-length(df[1,])]
  
  #########################################
  ##                ggplots              ##
  #########################################
  
  a <- ggplot(melted_df, aes(x = value, fill = variable)) + geom_density(alpha = 0.3) + theme_minimal()
  b <- ggplot(melted_df, aes(x = index, y = value, group = variable, color = variable)) + geom_point() + theme_minimal()
  c <- ggplot(melted_df, aes(x = index, y = value, group = variable, color = variable)) + geom_boxplot() + theme_minimal()
  
  ggsave(paste(outpath,"densities.pdf",sep = ""), plot = a, width = width, height = height)
  ggsave(paste(outpath,"cloud_point.pdf", sep = ""), plot = b, width = width, height = height)
  ggsave(paste(outpath,"box_plot.pdf", sep = ""), plot = c, width = width, height = height)
  
  #########################################
  ##                PCA                  ##
  #########################################
  
  complete_df <- df[complete.cases(df),]
  print("Dimension of complete cases :")
  print(dim(complete_df))
  t_complete_df <- t(complete_df)
  
  if (is.null(targets)){
    PCA <- prcomp(t_complete_df ,center = TRUE, scale. = T)
    
    pdf(paste(outpath,"boulder_plot.pdf", sep = ""), width = width, height = height)
    plot(PCA)
    dev.off()
    pdf(paste(outpath,"PCA.pdf", sep = ""), width = width, height = height)
    plot(PCA$x[,1],PCA$x[,2], pch = 19, xlab = paste("PC1 (",as.character(round(PCA$sdev[1]^2/sum(PCA$sdev^2)*100)),"%)"), ylab = paste("PC2 (",as.character(round(PCA$sdev[2]^2/sum(PCA$sdev^2)*100)),"%)"), main = "PCA of samples")
    text(PCA$x[,1],PCA$x[,2], labels = names(PCA$x[,1]), pos = 3)
    dev.off()
  }
  else
  {
    if (no_pca_label)
    {
      pcaPlot <- nicePCA(df = complete_df, targets, c(1,2,3), no_label = T)
    }
    else
    {
      pcaPlot <- nicePCA(df = complete_df, targets, c(1,2,3))
    }
    ggsave(file=paste(outpath,"/nice_PCA.pdf", sep = ""), pcaPlot, dpi = 300, width = width, height = height)
  }
  
  #########################################
  ##                heatmap              ##
  #########################################
  
  pheatmap(t_complete_df, show_colnames =  FALSE, filename = paste(outpath,"profil_heatmap.pdf", sep = ""), width = width, height = height)
  pheatmap(cor(complete_df, method = "spearman"), filename = paste(outpath,"correlation_heatmap.pdf", sep = ""), width = width, height = height)
}

#'\code{makeContrastsAlt}
#'
#'This function create a contrast matrix to be used by limma.
#'
#'@param targets A n*2 dataframe, where n is the number of samples. First column correspond to samples, second column correspond to conditions.
#'@param comparisons a list of numeric vectors. Each vector represent which condition should be conpared. Example :
#'c(2,-1) means that the first condition should be substracted from second condition. Vectors can be more than two element for complex contrasts.
#'@return a contrast matrix
makeContrastsAlt <- function(targets, comparisons)
{
  cont.matrix <- matrix(0,nrow = length(unique(targets$condition)), ncol = length(comparisons))
  i <- 1
  for (comparison in comparisons)
  {
    for (j in 1:length(comparison))
    {
      cont.matrix[abs(comparison[j]),i] <- cont.matrix[abs(comparison[j]),i]+(comparison[j]/abs(comparison[j]))
    }
    i <- i + 1
  }
  return(cont.matrix)
}

#'\code{checkInputs}
#'
#'This function makes sure that the input of runLimma are properly formatted
#'
#'@param measurments the measurment n*m dataframe (n is number of omic features, m is number of samples) where columns are ordered by conditions.
#'@param targets A n*2 dataframe, where n is the number of samples. First column correspond to samples, second column correspond to conditions.
#'@return TRUE if all is good, FALSE otherwise
checkInputs <- function(measurments, targets)
{
  if(class(measurments) != "data.frame")
  {
    error_message <- paste("The measurments argument should be a data.frame. It's currently a", paste(class(measurments), ".",sep = ""))
    return(list(FALSE, error_message))
  }
  else
  {
    if(dim(measurments)[1] == 0)
    {
      error_message <- "The measurments dataframe doesn't seem to contain any measurments..."
      return(list(FALSE, error_message))
    }
    else
    {
      if(dim(measurments)[2] == 0)
      {
        error_message <- "The measurments dataframe doesn't seem to contain any samples..."
        return(list(FALSE, error_message))
      }
      else
      {
        if(class(as.matrix(measurments)[,1]) != "numeric")
        {
          return(list(FALSE, "The measurments dataframe should contain only numerical values (or NAs)."))
        }
        else
        {
          if(class(targets) != "data.frame")
          {
            error_message <- paste("The targets argument should be a data.frame. It's currently a", paste(class(targets), ".",sep = ""))
            return(list(FALSE, error_message))
          }
          else
          {
            if(dim(targets)[2] < 2)
            {
              return(list(FALSE,"The targets dataframe should have at least two columns, sample names and conditions."))
            }
            else
            {
              if(dim(targets)[1] != dim(measurments)[2])
              {
                error_message <- paste("The targets dataframe should have as many samples (targets rows) as the measurements (measurments columns). Currently, the targets dataframe has", paste(dim(targets)[1], "samples and the measurements have", paste(dim(measurments)[2],"samples.")))
                return(list(FALSE, error_message))
              }
              else
              {
                #placeholder in case i think of more stuff to check
              }
            }
          }
        }
      }
    }
  }
  return(list(TRUE, "All seems to be in order..."))
}

#'\code{runLimma}
#'
#'This function is a wrapper of limma made to facilitate the use of limma differential analysis
#'
#'@param measurments the measurment n*m dataframe (n is number of omic features, m is number of samples) where columns are ordered by conditions.
#'@param targets A n*2 dataframe, where n is the number of samples. First column correspond to samples, second column correspond to conditions.
#'@param comparisons a list of numeric vectors. Each vector represent which condition should be conpared. Example :
#'c(2,-1) means that the first condition should be substracted from second condition. Vectors can be more than two element for complex contrasts.
#'@param regress_out in case the user which to exclude possible confounding factors from the analysis, the user can provide additional columns in the targets dataframe.
#'then, the confounding factor can be regressed out by indicating the number of the column of the target dataframe describing it. Only one factor can be regressed out at the present time.
#'@return a list. First element is the limma model fitted with the contrast matrix, this is the usual output of limma. Second element is the contrast matrix that was used. third element is the fitted limma object without contrasts.
runLimma <- function(measurements, targets, comparisons = NULL, regress_out = NULL)
{
  input_check <- checkInputs(measurements, targets)
  if (input_check[[1]]) #input has correct format
  {
    if (!is.null(comparisons))
    {
      if (!is.null(regress_out))
      {
        for (regressor in regress_out)
        {
          measurements <- removeBatchEffect(measurements, targets[,regressor])
        }
      }
      
      cont.matrix <- makeContrastsAlt(targets, comparisons)
      
      cont.matrix <- as.data.frame(cont.matrix)
      row.names(cont.matrix) <- unique(targets$condition)
      cont.matrix <- as.matrix(cont.matrix)
      
      fcond <- factor(targets$condition, levels = unique(targets$condition))
      
      design <- model.matrix(~0+fcond)
      design <- as.data.frame(design)
      names(design) <- unique(targets$condition)
      design <- as.matrix(design)
      
      print(cont.matrix)
      
      fit <- lmFit(measurements, design)
      fit2 <- contrasts.fit(fit, cont.matrix)
      fit2 <- eBayes(fit2)
      
      return(list(fit2, cont.matrix, fit))
    }
  }
  else
  {
    print(input_check[[2]])
    return(input_check[[1]])
  }
}

#'\code{ttopFormatter}
#'
#'This function is simply designed to format the toptable of limma with first column as gene identifiers instead of only row.names.
#'
#'@param ttop a toptable dataframe generated by the topTable function of limma
#'
#'@return a dataframe similar to the output of topTable function of limma but with first column as IDs instead of onyl row.names.
ttopFormatter <- function(ttop)
{
  ttop$ID <- row.names(ttop)
  ttop <- ttop[,c(7,1,2,3,4,5,6)]
  ttop <- ttop[complete.cases(ttop),]
  return(ttop)
}

#'\code{df_to_viper_regulon}
#'
#'This function is designed to generate a ready to use regulon object for viper
#'from a 3 column dataframe representation of a target set collection.
#'
#'@param df a dataframe of n*3 dimension. The first column corresponds the targets,
#'and the second column indicates which regulon does each target belongs to.
#'The third column corresponds to the weight and sign of the interaction between
#'a regulon and its targets.
#'
#'@return a list where each element is a regulon in the viper format. This list
#'is ready to be used as a regulon set in viper.
df_to_viper_regulon <- function(df)
{
  names(df) <- c("feature","pathway","sign")
  df <- df[complete.cases(df),]
  
  pathway_regulon <- list(0)
  i <- 1
  for(pathway in unique(df$pathway))
  {
    pathway_feature_list <- list(0)
    features <- df[df$pathway == pathway, 3]
    names(features) <- df[df$pathway == pathway, 1]
    pathway_feature_list[[1]] <- features
    pathway_feature_list[[2]] <- rep(1,length(features))
    names(pathway_feature_list) <- c("tfmode","likelihood")
    
    pathway_regulon[[i]] <- pathway_feature_list
    i <- i+1
  }
  names(pathway_regulon) <- unique(df$pathway)
  return(pathway_regulon)
}

#'\code{runProgenyFast}
#'
#'This function is designed to compute progeny pathway scores and assess there significance using a gene sampling based permutation strategy, for a series of experimental samples/contrasts.
#'
#'@param df A data.frame of n*m+1 dimension, where n is the number of omic features to be considered and m is the number of samples/contrasts.
#'The first column should be the identifiers of the omic features. These identifiers must be coherent with the identifers of the weight matrix.
#'@param weight_matrix A progeny coeficient matrix. the first column should be the identifiers of the omic features, and should be coherent with the identifiers provided in df.
#'@param k The number of permutations to be preformed to generate the null-distribution used to estimate significance of progeny scores. Default value is 10000.
#'@param z_score if true, the z-scores will be returned for the pathway activity estimations. Else, the function returns a normalised z-score value between -1 and 1.
#'@param get_nulldist if true, the null score distribution used for normalisation will be returned along with the actual normalised score data frame.
#'@return This function returns a list of two elements. The first element is a dataframe of p*m+1 dimensions, where p is the number of progeny pathways, and m is the number of samples/contrasts.
#'Each cell represent the significance of a progeny pathway score for one sample/contrast. The signifcance ranges between -1 and 1. The significance is equal to x*2-1, x being the quantile of the progeny pathway score with respect to the null distribution.
#'Thus, this significance can be interpreted as the equivalent of 1-p.value (two sided test over an empirical distribution) with the sign indicating the direction of the regulation.
#'The sceond element is the null distribution list (a null distribution is generated for each sample/contrast).
runProgenyFast <- function(df,weight_matrix,k = 10000, z_scores = T, get_nulldist = F)
{
  resList <- list()
  if(get_nulldist)
  {
    nullDist_list <- list()
  }
  
  for(i in 2:length(df[1,]))
  {
    current_df <- df[,c(1,i)]
    current_df <- current_df[complete.cases(current_df),]
    t_values <- current_df[,2]
    
    current_weights <- weight_matrix
    
    names(current_df)[1] <- "ID"
    names(current_weights)[1] <- "ID"
    
    common_ids <- merge(current_df, current_weights, by = "ID")
    common_ids <- common_ids$ID
    common_ids <- as.character(common_ids)
    
    row.names(current_df) <- current_df$ID
    current_df <- as.data.frame(current_df[common_ids,-1])
    
    row.names(current_weights) <- current_weights$ID
    current_weights <- as.data.frame(current_weights[common_ids,-1])
    
    current_mat <- as.matrix(current_df)
    current_weights <- t(current_weights)
    
    scores <- as.data.frame(current_weights %*% current_mat)
    
    null_dist_t <- replicate(k, sample(t_values,length(current_mat[,1]), replace = F))
    
    null_dist_scores <- current_weights %*% null_dist_t
    
    if(get_nulldist)
    {
      nullDist_list[[i-1]] <- null_dist_scores
    }
    
    if(z_scores)
    {
      scores$mean <- apply(null_dist_scores,1,mean)
      scores$sd <- apply(null_dist_scores,1,sd)
      resListCurrent <- (scores[,1]-scores[,2])/scores[,3]
      names(resListCurrent) <- names(weight_matrix[,-1])
      resList[[i-1]] <- resListCurrent
    }
    else
    {
      for(j in 1:length(weight_matrix[,-1]))
      {
        ecdf_function <- ecdf(null_dist_scores[j,])
        scores[j,1] <- ecdf_function(scores[j,1])
      }
      score_probas <- scores*2-1
      
      resListCurrent <- score_probas[,1]
      names(resListCurrent) <- names(weight_matrix[,-1])
      resList[[i-1]] <- resListCurrent
    }
  }
  names(resList) <- names(df[,-1])
  resDf <- as.data.frame(resList)
  if(get_nulldist)
  {
    names(nullDist_list) <- names(df[,-1])
    return(list(resDf, nullDist_list))
  }
  else
  {
    return(resDf)
  }
  
}

#'\code{progenyScatter}
#'
#'This function generate a series of scatter plot with marginal distribution (in the form of an arrangeGrob object), for each progeny pathway and sample/contrast.
#'Each scatter plot has progeny weights as x axis and the gene level stat used to compute progeny score as y axis.
#'The marginal distribution of the gene level stats is displayed on the right of the plot to give a visual support of the significnce of each gene contributing to the progeny pathway score.
#'The colors green and red represent respectivelly positive and negative contribution of genes to the progeny pathway.
#'For each gene contribution, 4 cases are possible, as the combinaisons of the sign of the gene level stat and the sign of the gene level weigth.
#'Positive weight will lead to a positive(green)/negative(red) gene contribution if the gene level stat is positive/negative.
#'Negative weigth will lead to a negative(red)/positive(green) gene contribution if the gene level stat is positive/negative.
#'
#'@param df a n*m data frame, where n is the number of omic features (genes). m isn't really important, as long as at least one column corespond to a sample or contrast statistic. One of the column should correspond to the gene symboles.
#'@param cm a progeny coeficient matrix. One of the column should be the gene symboles.
#'@param dfID an integer corresponding to the column number of the gene identifiers of df.
#'@param weightID an integer corresponding to the column number of the gene identifiers of the weight matrix.
#'@param statname The neame of the stat used, to be displayed on the plot
#'@return The function returns a list of list of arrangeGrob object.The first level list elements correspond to samples/contrasts. The second level correspond to pathways.
#'The plots can be saved in a pdf format using the saveProgenyPlots function.
progenyScatter <- function(df,weight_matrix,dfID = 1, weightID = 1, statName = "gene stats")
{
  plot_list_contrasts <- list(0)
  for (i in 2:length(df[1,]))
  {
    plot_list_pathways <- list(0)
    for (j in 2:length(weight_matrix[1,]))
    {
      sub_df <- df[,c(dfID,i)]
      
      
      
      pathway_weights <- weight_matrix[,c(weightID,j)]
      names(sub_df) <- c("ID","stat")
      
      minstat <- min(sub_df$stat)
      maxstat <- max(sub_df$stat)
      histo <- ggplot(sub_df, aes(x = stat, fill = "blue")) + geom_density() + coord_flip() + scale_fill_manual( values = c("#00c5ff")) + xlim(minstat, maxstat) + theme_minimal() + theme(legend.position = "none", axis.text.x = element_blank(), axis.ticks.x = element_blank(), axis.title.y = element_blank(), axis.text.y = element_blank(), axis.ticks.y = element_blank(), panel.grid.major = element_blank(), panel.grid.minor = element_blank())
      
      names(pathway_weights) <- c("ID","weight")
      pathway_weights <- pathway_weights[pathway_weights$weight != 0,]
      
      percentile <- ecdf(sub_df$stat)
      
      sub_df <- merge(sub_df,pathway_weights,by = "ID")
      
      sub_df$color <- "3"
      sub_df[(sub_df$weight > 0 & sub_df$stat > 0),"color"] <- "1"
      sub_df[(sub_df$weight > 0 & sub_df$stat < 0),"color"] <- "2"
      sub_df[(sub_df$weight < 0 & sub_df$stat > 0),"color"] <- "2"
      sub_df[(sub_df$weight < 0 & sub_df$stat < 0),"color"] <- "1"
      
      sub_df[(percentile(sub_df$stat) < .95 & percentile(sub_df$stat) > .05),1] <- NA
      
      print(paste("weights of ",names(weight_matrix)[j], sep = ""))
      
      title <- paste("weights of ",names(weight_matrix)[j], sep = "")
      
      scatterplot <- ggplot(sub_df, aes(x = weight, y = stat, color = color)) + geom_point() +
        # scale_colour_manual(values = c("#15ff00","#ff0000","#c9c9c9")) + #green and red
        scale_colour_manual(values = c("red","royalblue3","grey")) +
        geom_label_repel(aes(label = ID)) +
        ylim(minstat, maxstat) + theme_minimal() + theme(legend.position = "none") + geom_vline(xintercept = 0, linetype = 'dotted') + geom_hline(yintercept = 0, linetype = 'dotted') + labs(x = title, y = statName)
      
      lay <- t(as.matrix(c(1,1,1,1,2)))
      gg <- arrangeGrob(scatterplot, histo, nrow = 1, ncol = 2, layout_matrix = lay)
      
      #grid.arrange(gg)
      plot_list_pathways[[j-1]] <- gg
    }
    names(plot_list_pathways) <- names(weight_matrix[,-weightID])
    plot_list_contrasts[[i-1]] <- plot_list_pathways
  }
  return(plot_list_contrasts)
}

#'\code{volcano_nice}
#'
#'This function is designed to generate a stylish and practical volcano plot to visual the result of a differential analisys, with simple required inputs.
#'The plot features two bi-symptotic curves to give a visual support for p-value and fold change threshold.
#'
#'@param df a dataframe of n*m dimension, where n is the number of omic features (genes,protein,etc...) and m is at least 3 (identifiers, foldchanges and p-values).
#'@param hAss the p-value threshold (example : 0.05)
#'@param FCIndex the column number corresponding to the foldchanges
#'@param pValIndex the column number corresponding to the p-values
#'@param IDIndex the column number corresponding to the identifiers
#'@param vAss the foldchange threshold (example : 0.5)
#'@param label a boolean argument to indicate if the labels of the significant genes should be displayed or not (maximum 30 labels)
#'@param straight a boolean argument to indicate if the plot should feature bi-symptotic curves or straight lines to visualise the thresholds.
#'@param nlabels number of labels to display
#'@param manual_labels a vector of labels that will be kept even if they are not in the top "nlabels"
#'
#'@return a ggplot object of the volcano plot
volcano_nice <- function (df, hAss = 0.05, FCIndex, pValIndex, IDIndex, vAss = NULL,
                          label = FALSE, straight = FALSE, nlabels, manual_labels = NA)
{
  df <- df[complete.cases(df), ]
  names(df)[1] <- "X1"
  hAssOri <- hAss
  hAss <- -log(hAss)
  names(df) <- gsub("adj.P.Val", "FDR", names(df))
  names(df)[FCIndex] <- "logFC"
  names(df)[pValIndex] <- "adj.P.Val"
  if (max(abs(df[, FCIndex])) >= 1) {
    xlimAbs <- ceiling(max(abs(df[, FCIndex])))
    ylimAbs <- ceiling(max(abs(-log(df[, pValIndex]))))
  }
  else {
    xlimAbs <- max(abs(df[, FCIndex]))
    ylimAbs <- max(abs(-log(df[, pValIndex])))
  }
  if (is.null(vAss)) {
    vAss <- xlimAbs/10
  }
  xneg <- function(x) abs(hAss - 1 + x/(x + vAss))
  xpos <- function(x) abs(hAss - 1 + x/(x - vAss))
  test <- function(x, y, vAss) {
    if (x < -vAss) {
      if (xneg(x) < -log(y)) {
        return("1")
      }
      else {
        return("0")
      }
    }
    else {
      if (x > vAss) {
        if (xpos(x) < -log(y)) {
          return("1")
        }
        else {
          return("0")
        }
      }
      else {
        return("0")
      }
    }
  }
  if (straight) {
    df$couleur <- ifelse(abs(df$logFC) >= vAss & df$adj.P.Val <=
                           hAssOri, "1", "0")
  }
  else {
    df$couleur <- "0"
    df$couleur <- apply(df, 1, FUN = function(x) test(as.numeric(x[FCIndex]),
                                                      as.numeric(x[pValIndex]), vAss))
  }
  df <- df[order(df$adj.P.Val, decreasing = F), ]
  df$condLabel <- df[, IDIndex]
  df[df$couleur == "0", "condLabel"] <- NA
  labels_to_keep <- c(df[c(1:nlabels), "condLabel"],manual_labels)
  df[!(df$condLabel %in% labels_to_keep), "condLabel"] <- NA
  df$couleur <- ifelse(df$couleur == "1" & df$logFC < 0, "2",
                       df$couleur)
  if (label) {
    a <- ggplot(df, aes(x = logFC, y = -log(adj.P.Val), color = couleur)) +
      geom_point(alpha = 0.5) + geom_label_repel(aes(label = condLabel)) +
      stat_function(fun = xneg, xlim = c(-xlimAbs, -vAss),
                    color = "black", alpha = 0.7) + ylim(c(0, ylimAbs)) +
      xlim(c(-xlimAbs, xlimAbs)) + stat_function(fun = xpos,
                                                 xlim = c(vAss, xlimAbs), color = "black", alpha = 0.7) +
      scale_colour_manual(values = c("grey30", "red",
                                     "royalblue3")) + theme_minimal() + theme(legend.position = "none")
  }
  else {
    if (straight) {
      a <- ggplot(df, aes(x = logFC, y = -log(adj.P.Val),
                          color = couleur)) + geom_point(alpha = 0.5) +
        geom_vline(xintercept = -vAss, color = "blue") +
        geom_vline(xintercept = vAss, color = "blue") +
        ylim(c(0, ylimAbs)) + xlim(c(-xlimAbs, xlimAbs)) +
        geom_hline(yintercept = hAss, color = "red") +
        scale_colour_manual(values = c("grey30", "red",
                                       "royalblue3")) + theme_minimal() + theme(legend.position = "none")
    }
    else {
      a <- ggplot(df, aes(x = logFC, y = -log(adj.P.Val),
                          color = couleur)) + geom_point(alpha = 0.5) +
        stat_function(fun = xneg, xlim = c(-xlimAbs,
                                           -vAss), color = "black", alpha = 0.7) + ylim(c(0,
                                                                                          ylimAbs)) + xlim(c(-xlimAbs, xlimAbs)) + stat_function(fun = xpos,
                                                                                                                                                 xlim = c(vAss, xlimAbs), color = "black", alpha = 0.7) +
        scale_colour_manual(values = c("grey30", "red",
                                       "royalblue3")) + theme_minimal() + theme(legend.position = "none")
    }
  }
  return(a)
}

#'\code{magicPlotMakerLight}
#'
#'This function is designed to generate and save a battery of plots aimed at helping visualise a measurments dataframe.
#'The function generate 3 plots to directly visualise measurements in the form of a cloud of points, a series of boxplots and surperimposed density curves.
#'It also genereate a pca plot (using nicePCA unction if a targets table is provided).
#'Finally it generates two heatmap, on directly clustering over the measurments and another one performing a clustring over the cross-correlation matrix of the samples.
#'The plots are directly saved to a folder. Nothing is returned.
#'
#'@param df the measurment n*m dataframe (n is number of omic features, m is number of samples) where columns are ordered by conditions.
#'@param targets A n*2 dataframe, where n is the number of samples. First column correspond to samples, second column correspond to conditions.
magicPlotMakerLight <- function(df, targets = NULL, no_pca_label = FALSE)
{
  
  
  if (!is.null(targets))
  {
    df_and_targets <- make_df_and_targets_great_again(df,targets)
    df <- df_and_targets[[1]]
    targets <- df_and_targets[[2]]
  }
  
  ##This part is just to generate the melted dataframe for ggplot
  df$ID <- row.names(df)
  
  melted_df <- reshape::melt(df)
  index <- c(1:length(melted_df[,1]))
  
  df <- df[,-length(df[1,])]
  
  #########################################
  ##                ggplots              ##
  #########################################
  
  violins <- ggplot(melted_df, aes(x = index, y = value, group = variable, color = variable)) + geom_violin() + theme_minimal()
  
  # plot(violins)
  
  complete_df <- df[complete.cases(df),]
  
  t_complete_df <- t(complete_df)
  if (is.null(targets)){
    PCA <- prcomp(t_complete_df ,center = TRUE, scale. = T)
    pcaPlot <- plot(PCA$x[,1],PCA$x[,2], pch = 19, xlab = paste("PC1 (",as.character(round(PCA$sdev[1]^2/sum(PCA$sdev^2)*100)),"%)"), ylab = paste("PC2 (",as.character(round(PCA$sdev[2]^2/sum(PCA$sdev^2)*100)),"%)"), main = "PCA of samples")
    text(PCA$x[,1],PCA$x[,2], labels = names(PCA$x[,1]), pos = 3)
  }
  else
  {
    if (no_pca_label)
    {
      pcaPlot <- nicePCA(df = complete_df, targets, c(1,2,3), no_label = T)
    }
    else
    {
      pcaPlot <- nicePCA(df = complete_df, targets, c(1,2,3))
    }
  }
  # plot(pcaPlot)
  return(list(violins,pcaPlot))
}


plotTF <- function(TF, geneLevelStats, regulon_df)
{
  names(geneLevelStats) <- c("ID","stat")
  targets <- regulon_df[regulon_df$TF == TF,]
  names(targets) <- c("ID","TF","sign")
  target_stats <- merge(geneLevelStats,targets, by = "ID")
  target_stats$stat <- target_stats$stat * target_stats$sign
  target_stats <- target_stats[order(target_stats$stat, decreasing = T),]
  target_stats <- unique(target_stats)
  target_stats$ID <- factor(target_stats$ID, levels = target_stats$ID)
  
  
  
  plot(ggplot(target_stats,aes(x = ID, y  = stat, fill = stat))+ geom_bar(stat = "identity"))
}
